{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# progress bar imports\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRoot = 'data'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get caltech dataset\n",
    "batch_size = 64\n",
    "trainSet = datasets.CIFAR10(root=dataRoot, train=True, download=True, transform=transforms.ToTensor())\n",
    "testSet = datasets.CIFAR10(root=dataRoot, train=False, download=True, transform=transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)\n",
    "testLoader = DataLoader(testSet, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 6\n",
      "shape torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "firstDatapoint = trainSet[0]\n",
    "firstImage = firstDatapoint[0]\n",
    "firstLabel = firstDatapoint[1]\n",
    "print(\"label\", firstLabel)\n",
    "print(\"shape\", firstImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.name = 'CifarNetwork'\n",
    "        # TODO what happens when kernel size is even?\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1) # 32x32 -> 30x30, no padding\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1) # 30x30 -> 26x26\n",
    "        \n",
    "        self.batch_flattener = nn.Flatten(start_dim=1) # make flat from dim 1\n",
    "        \n",
    "        self.fc1 = nn.Linear(26*26*64, 10)\n",
    "        self.activation = nn.LeakyReLU(0.01)\n",
    "        self.LogSoftmax = nn.LogSoftmax(dim=1) # For batch, output is in dim 1 for each image.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_flattener(out)\n",
    "#         print(\"shape after flattening\", out.shape)\n",
    "        out = self.fc1(out)\n",
    "        out = self.activation(out)\n",
    "        return self.LogSoftmax(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarNetwork(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (batch_flattener): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=43264, out_features=10, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.01)\n",
      "  (LogSoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CifarNetwork().to(device)\n",
    "print(model)\n",
    "lossFunc = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/782 [00:00<01:29,  8.77batch/s, accuracy=4.69, batch_loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▊        | 144/782 [00:16<01:11,  8.88batch/s, accuracy=17.2, batch_loss=1.78]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-ffa11241cbd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mtepoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def saveCheckpoint(epoch, model, optimizer):\n",
    "    \n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "        \n",
    "    }, f\"{model.name}-checkpoint-{epoch}\")\n",
    "\n",
    "# train\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "        for images, labels in tepoch:\n",
    "            count += 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             print(\"label shape\", labels.shape)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = lossFunc(output, labels)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "            predictions1 = output.argmax(dim=1)\n",
    "#             predictions2 = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "#             print(\"prediction1\", predictions1)\n",
    "#             print(\"predictions2\", predictions2)\n",
    "            correct = (predictions == labels).sum()\n",
    "            accuracy = correct / labels.size(0)\n",
    "\n",
    "#             if count % 6 == 0:\n",
    "#                 print(f\"Epoch progress: {round(count * 100/len(trainLoader))}%\")\n",
    "                \n",
    "            tepoch.set_postfix(batch_loss=batch_loss.item(), accuracy=100. * accuracy.item())\n",
    "#             sleep(0.1)\n",
    "\n",
    "        \n",
    "    # checkpoint\n",
    "    if epoch % 5 == 0:\n",
    "        saveCheckpoint(epoch, model, optimizer)\n",
    "            \n",
    "    print(f\"Epoch{epoch}, Average training loss: {epoch_loss / len(trainLoader)}\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
