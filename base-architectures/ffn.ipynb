{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system?True\n",
      "CUDA version: 10.2\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "        \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('', download=True, train=True, transform=transforms.ToTensor()) # ToTensor normalizes the image tensor [0, 255] -> [0, 1]\n",
    "testset = datasets.MNIST('', download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainset[0] # first data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the first image: torch.Size([1, 28, 28])\n",
      "label: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = x[0]\n",
    "label = x[1]\n",
    "print(\"shape of the first image:\", image.shape) # This has the batch dimension.\n",
    "print(\"label:\", label)\n",
    "image.reshape(-1, 784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration\n",
    "input_size = 784\n",
    "hidden_size = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size[0]) # params = 784 * 128\n",
    "        self.layer2 = nn.Linear(hidden_size[0], hidden_size[1]) # params = 128 * 64\n",
    "        self.layer3 = nn.Linear(hidden_size[1], output_size) # params = 64*10\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.LogSoftmax = nn.LogSoftmax(dim=1) # dim = 0 if we are consuming without the batch dimension, 1 if batch.\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.layer1(x))\n",
    "        out = self.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "#         print(\"output before softmax\", out)\n",
    "        out = self.LogSoftmax(out)\n",
    "#         print(\"output after softmax\", out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (LogSoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(input_size, hidden_size, output_size)\n",
    "model.to(device) # don't need assignment model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4122, -2.4036, -2.2590, -2.4293, -2.1535, -2.2461, -2.2768, -2.4252,\n",
       "         -2.2977, -2.1717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.forward(image.flatten().unsqueeze(dim=0)) # batch conversion when LogSoftmax expects a batch dimension\n",
    "model.forward(image.reshape(-1, 784).to(device))\n",
    "# model.forward(image.flatten()) # no batch conversion when LogSoftmax expects a single datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch0, Average training loss: 0.21934600315019012\n",
      "epoch: 1\n",
      "Epoch1, Average training loss: 0.20857365878183703\n",
      "epoch: 2\n",
      "Epoch2, Average training loss: 0.19797064492236705\n",
      "epoch: 3\n",
      "Epoch3, Average training loss: 0.18869457457826208\n",
      "epoch: 4\n",
      "Epoch4, Average training loss: 0.17991030223365787\n",
      "epoch: 5\n",
      "Epoch5, Average training loss: 0.17206940696890483\n",
      "epoch: 6\n",
      "Epoch6, Average training loss: 0.16489926258177517\n",
      "epoch: 7\n",
      "Epoch7, Average training loss: 0.15708390915238146\n",
      "epoch: 8\n",
      "Epoch8, Average training loss: 0.15064337494562685\n",
      "epoch: 9\n",
      "Epoch9, Average training loss: 0.14432046441301735\n",
      "epoch: 10\n",
      "Epoch10, Average training loss: 0.13830590589261893\n",
      "epoch: 11\n",
      "Epoch11, Average training loss: 0.13279174375476868\n",
      "epoch: 12\n",
      "Epoch12, Average training loss: 0.1275785527209928\n",
      "epoch: 13\n",
      "Epoch13, Average training loss: 0.12259984824623761\n",
      "epoch: 14\n",
      "Epoch14, Average training loss: 0.11785550653112373\n",
      "epoch: 15\n",
      "Epoch15, Average training loss: 0.11346915383725914\n",
      "epoch: 16\n",
      "Epoch16, Average training loss: 0.10979284962385034\n",
      "epoch: 17\n",
      "Epoch17, Average training loss: 0.10567636792260066\n",
      "epoch: 18\n",
      "Epoch18, Average training loss: 0.10185398365746239\n",
      "epoch: 19\n",
      "Epoch19, Average training loss: 0.09857974760830085\n",
      "epoch: 20\n",
      "Epoch20, Average training loss: 0.09525451637002261\n",
      "epoch: 21\n",
      "Epoch21, Average training loss: 0.09205157063039604\n",
      "epoch: 22\n",
      "Epoch22, Average training loss: 0.08926310494486521\n",
      "epoch: 23\n",
      "Epoch23, Average training loss: 0.08638266848424064\n",
      "epoch: 24\n",
      "Epoch24, Average training loss: 0.08384070179409293\n",
      "epoch: 25\n",
      "Epoch25, Average training loss: 0.08115788812397608\n",
      "epoch: 26\n",
      "Epoch26, Average training loss: 0.07856944624656267\n",
      "epoch: 27\n",
      "Epoch27, Average training loss: 0.0764607443232963\n",
      "epoch: 28\n",
      "Epoch28, Average training loss: 0.07393627760630013\n",
      "epoch: 29\n",
      "Epoch29, Average training loss: 0.07201646959611666\n",
      "epoch: 30\n",
      "Epoch30, Average training loss: 0.06993275303105667\n",
      "epoch: 31\n",
      "Epoch31, Average training loss: 0.06804949045578428\n",
      "epoch: 32\n",
      "Epoch32, Average training loss: 0.06592140224392909\n",
      "epoch: 33\n",
      "Epoch33, Average training loss: 0.06431157640598492\n",
      "epoch: 34\n",
      "Epoch34, Average training loss: 0.0625040310545207\n",
      "epoch: 35\n",
      "Epoch35, Average training loss: 0.061065083316493546\n",
      "epoch: 36\n",
      "Epoch36, Average training loss: 0.059609794777248114\n",
      "epoch: 37\n",
      "Epoch37, Average training loss: 0.05788358098922619\n",
      "epoch: 38\n",
      "Epoch38, Average training loss: 0.056455980853310654\n",
      "epoch: 39\n",
      "Epoch39, Average training loss: 0.055011304544666205\n",
      "epoch: 40\n",
      "Epoch40, Average training loss: 0.053710694066377906\n",
      "epoch: 41\n",
      "Epoch41, Average training loss: 0.05211574578238751\n",
      "epoch: 42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5fc2da2d6f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#         print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#         print(loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# clear previous grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute new grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update parameters with new grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch37\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    190\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch:\", epoch)\n",
    "    epoch_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         print(\"device\", device)\n",
    "#         print(\"images device\", images.device)\n",
    "        images = images.reshape(-1, 784) # rows of image vectors\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(images) # output  = rows of single values\n",
    "#         print(\"shape of output for batch\", output.shape)\n",
    "#         print(\"shape of labels for batch\", labels.shape)\n",
    "        \n",
    "        batch_loss = lossFunction(output, labels) # here labels are actually saying which index is the ground truth of each output.\n",
    "#         print(output)\n",
    "#         print(labels)\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad() # clear previous grad\n",
    "        batch_loss.backward() # compute new grads\n",
    "        optimizer.step() # update parameters with new grads\n",
    "        \n",
    "        epoch_loss += batch_loss.item() # convert to scalar\n",
    "        \n",
    "        # save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                \n",
    "            }, f'checkpoint-{epoch}.pt')\n",
    "        \n",
    "    print(f\"Epoch{epoch}, Average training loss: {epoch_loss / len(train_loader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 93.68\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels  in test_loader:\n",
    "        labels = labels.to(device)\n",
    "        images = images.reshape(-1, 784).to(device)\n",
    "        out = model(images)\n",
    "#         print(\"shape of out\", out.shape)\n",
    "#         print(\"shape of torch.max(out, 1)\")\n",
    "#         print(torch.max(out, 1)) # max of every row which is at dim 1\n",
    "#         break\n",
    "        _, predicted = torch.max(out, 1) # _ is the max value in row, predicted is actually the argmax (or index of that value)\n",
    "#         print(\"labels size\", labels.shape[0])\n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "#         break\n",
    "    print(f\"Testing accuracy: {100 * correct / total}\")\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, 'ffn_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (LogSoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model with state_dict\n",
    "loadedModel = Network(input_size, hidden_size, output_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "checkpoint = torch.load('checkpoint-10.pt')\n",
    "loadedModel.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "loadedModel.to(device)\n",
    "loadedModel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 95.86\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels  in test_loader:\n",
    "        labels = labels.to(device)\n",
    "        images = images.reshape(-1, 784).to(device)\n",
    "        out = loadedModel(images)\n",
    "#         print(\"shape of out\", out.shape)\n",
    "#         print(\"shape of torch.max(out, 1)\")\n",
    "#         print(torch.max(out, 1)) # max of every row which is at dim 1\n",
    "#         break\n",
    "        _, predicted = torch.max(out, 1) # _ is the max value in row, predicted is actually the argmax (or index of that value)\n",
    "#         print(\"labels size\", labels.shape[0])\n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "#         break\n",
    "    print(f\"Testing accuracy: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
